name: 🧪 SafeWork Integration Tests

on:
  push:
    branches: [master, develop]
    paths:
      - 'app/**'
      - 'tests/**'
      - 'scripts/**'
      - 'docker-compose.yml'
      - '.github/workflows/integration-tests.yml'
  pull_request:
    branches: [master, develop]
    paths:
      - 'app/**'
      - 'tests/**'
      - 'scripts/**'
      - 'docker-compose.yml'
  schedule:
    # Run integration tests daily at 2 AM KST (5 PM UTC)
    - cron: '0 17 * * *'
  workflow_dispatch:
    inputs:
      test_category:
        description: 'Test category to run'
        required: false
        default: 'all'
        type: choice
        options:
          - all
          - api
          - database
          - container
          - monitoring
          - e2e
          - critical
      skip_slow_tests:
        description: 'Skip slow E2E tests'
        required: false
        default: false
        type: boolean

env:
  REGISTRY: registry.jclee.me
  REGISTRY_USER: admin
  TEST_TIMEOUT: 600
  PARALLEL_WORKERS: 2

jobs:
  setup-test-environment:
    name: 🏗️ Setup Test Environment
    runs-on: ubuntu-latest
    timeout-minutes: 10
    outputs:
      test-url: ${{ steps.setup.outputs.test-url }}
      test-ready: ${{ steps.health-check.outputs.ready }}
    
    steps:
      - name: 📥 Checkout Repository
        uses: actions/checkout@v4

      - name: 🐍 Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
          cache: 'pip'

      - name: 📦 Install Test Dependencies
        run: |
          pip install --upgrade pip
          pip install -r tests/requirements.txt

      - name: 🔧 Setup Test Configuration
        id: setup
        run: |
          # Generate unique test URLs for this workflow run
          TEST_URL="https://safework.jclee.me"
          echo "test-url=$TEST_URL" >> $GITHUB_OUTPUT
          echo "TEST_BASE_URL=$TEST_URL" >> $GITHUB_ENV

      - name: 🏥 Health Check
        id: health-check
        run: |
          echo "Checking service health..."
          max_attempts=30
          attempt=1
          
          while [ $attempt -le $max_attempts ]; do
            if curl -f -s "$TEST_BASE_URL/health" > /dev/null; then
              echo "✅ Service is healthy"
              echo "ready=true" >> $GITHUB_OUTPUT
              exit 0
            fi
            
            echo "⏳ Attempt $attempt/$max_attempts - Service not ready, waiting..."
            sleep 10
            attempt=$((attempt + 1))
          done
          
          echo "❌ Service health check failed after $max_attempts attempts"
          echo "ready=false" >> $GITHUB_OUTPUT
          exit 1
        env:
          TEST_BASE_URL: ${{ steps.setup.outputs.test-url }}

  api-integration-tests:
    name: 🔌 API Integration Tests
    runs-on: ubuntu-latest
    needs: setup-test-environment
    if: needs.setup-test-environment.outputs.test-ready == 'true'
    timeout-minutes: 20
    
    steps:
      - name: 📥 Checkout Repository
        uses: actions/checkout@v4

      - name: 🐍 Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
          cache: 'pip'

      - name: 📦 Install Dependencies
        run: |
          pip install --upgrade pip
          pip install -r tests/requirements.txt

      - name: 🧪 Run API Integration Tests
        run: |
          python -m pytest \
            -m "api" \
            --junitxml=test-results/junit-api.xml \
            --html=test-results/report-api.html \
            --self-contained-html \
            --cov=app \
            --cov-report=xml:test-results/coverage-api.xml \
            --cov-report=html:test-results/coverage-api \
            -n ${{ env.PARALLEL_WORKERS }} \
            --timeout=${{ env.TEST_TIMEOUT }} \
            -v \
            tests/
        env:
          TEST_BASE_URL: ${{ needs.setup-test-environment.outputs.test-url }}

      - name: 📊 Upload Test Results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: api-test-results
          path: test-results/
          retention-days: 30

      - name: 📈 Upload Coverage
        uses: codecov/codecov-action@v3
        if: always()
        with:
          file: test-results/coverage-api.xml
          flags: api-tests
          name: api-coverage

  database-integration-tests:
    name: 🗄️ Database Integration Tests
    runs-on: ubuntu-latest
    needs: setup-test-environment
    if: needs.setup-test-environment.outputs.test-ready == 'true'
    timeout-minutes: 15
    
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_DB: safework_test
          POSTGRES_USER: safework
          POSTGRES_PASSWORD: safework2024
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432

      redis:
        image: redis:7
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 6379:6379

    steps:
      - name: 📥 Checkout Repository
        uses: actions/checkout@v4

      - name: 🐍 Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
          cache: 'pip'

      - name: 📦 Install Dependencies
        run: |
          pip install --upgrade pip
          pip install -r tests/requirements.txt

      - name: 🧪 Run Database Integration Tests
        run: |
          python -m pytest \
            -m "database" \
            --junitxml=test-results/junit-database.xml \
            --html=test-results/report-database.html \
            --self-contained-html \
            --cov=app \
            --cov-report=xml:test-results/coverage-database.xml \
            --cov-report=html:test-results/coverage-database \
            -n ${{ env.PARALLEL_WORKERS }} \
            --timeout=${{ env.TEST_TIMEOUT }} \
            -v \
            tests/
        env:
          TEST_BASE_URL: ${{ needs.setup-test-environment.outputs.test-url }}
          TEST_DB_URL: postgresql://safework:safework2024@localhost:5432/safework_test
          TEST_REDIS_URL: redis://localhost:6379/1

      - name: 📊 Upload Test Results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: database-test-results
          path: test-results/
          retention-days: 30

      - name: 📈 Upload Coverage
        uses: codecov/codecov-action@v3
        if: always()
        with:
          file: test-results/coverage-database.xml
          flags: database-tests
          name: database-coverage

  container-integration-tests:
    name: 🐳 Container Integration Tests
    runs-on: ubuntu-latest
    needs: setup-test-environment
    if: needs.setup-test-environment.outputs.test-ready == 'true'
    timeout-minutes: 25
    
    steps:
      - name: 📥 Checkout Repository
        uses: actions/checkout@v4

      - name: 🐍 Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
          cache: 'pip'

      - name: 📦 Install Dependencies
        run: |
          pip install --upgrade pip
          pip install -r tests/requirements.txt

      - name: 🧪 Run Container Integration Tests
        run: |
          python -m pytest \
            -m "container" \
            --junitxml=test-results/junit-container.xml \
            --html=test-results/report-container.html \
            --self-contained-html \
            --cov=app \
            --cov-report=xml:test-results/coverage-container.xml \
            --cov-report=html:test-results/coverage-container \
            -n ${{ env.PARALLEL_WORKERS }} \
            --timeout=${{ env.TEST_TIMEOUT }} \
            -v \
            tests/
        env:
          TEST_BASE_URL: ${{ needs.setup-test-environment.outputs.test-url }}

      - name: 📊 Upload Test Results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: container-test-results
          path: test-results/
          retention-days: 30

  monitoring-tests:
    name: 📈 Monitoring & Performance Tests
    runs-on: ubuntu-latest
    needs: setup-test-environment
    if: needs.setup-test-environment.outputs.test-ready == 'true'
    timeout-minutes: 30
    
    steps:
      - name: 📥 Checkout Repository
        uses: actions/checkout@v4

      - name: 🐍 Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
          cache: 'pip'

      - name: 📦 Install Dependencies
        run: |
          pip install --upgrade pip
          pip install -r tests/requirements.txt

      - name: 🧪 Run Monitoring Tests
        run: |
          python -m pytest \
            -m "monitoring" \
            --junitxml=test-results/junit-monitoring.xml \
            --html=test-results/report-monitoring.html \
            --self-contained-html \
            --cov=app \
            --cov-report=xml:test-results/coverage-monitoring.xml \
            --cov-report=html:test-results/coverage-monitoring \
            --timeout=${{ env.TEST_TIMEOUT }} \
            -v \
            tests/
        env:
          TEST_BASE_URL: ${{ needs.setup-test-environment.outputs.test-url }}

      - name: 📊 Upload Test Results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: monitoring-test-results
          path: test-results/
          retention-days: 30

  e2e-tests:
    name: 🎭 End-to-End Tests
    runs-on: ubuntu-latest
    needs: setup-test-environment
    if: needs.setup-test-environment.outputs.test-ready == 'true' && github.event.inputs.skip_slow_tests != 'true'
    timeout-minutes: 45
    
    steps:
      - name: 📥 Checkout Repository
        uses: actions/checkout@v4

      - name: 🐍 Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
          cache: 'pip'

      - name: 🌐 Setup Chrome
        uses: browser-actions/setup-chrome@latest
        with:
          chrome-version: stable

      - name: 📦 Install Dependencies
        run: |
          pip install --upgrade pip
          pip install -r tests/requirements.txt

      - name: 🧪 Run End-to-End Tests
        run: |
          python -m pytest \
            -m "e2e" \
            --junitxml=test-results/junit-e2e.xml \
            --html=test-results/report-e2e.html \
            --self-contained-html \
            --maxfail=3 \
            --timeout=${{ env.TEST_TIMEOUT }} \
            -v \
            tests/
        env:
          TEST_BASE_URL: ${{ needs.setup-test-environment.outputs.test-url }}

      - name: 📊 Upload Test Results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: e2e-test-results
          path: test-results/
          retention-days: 30

      - name: 📸 Upload Screenshots
        uses: actions/upload-artifact@v4
        if: failure()
        with:
          name: e2e-screenshots
          path: test-results/screenshots/
          retention-days: 7

  critical-tests:
    name: 🚨 Critical System Tests
    runs-on: ubuntu-latest
    needs: [api-integration-tests, database-integration-tests, container-integration-tests]
    if: needs.setup-test-environment.outputs.test-ready == 'true'
    timeout-minutes: 15
    
    steps:
      - name: 📥 Checkout Repository
        uses: actions/checkout@v4

      - name: 🐍 Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
          cache: 'pip'

      - name: 📦 Install Dependencies
        run: |
          pip install --upgrade pip
          pip install -r tests/requirements.txt

      - name: 🧪 Run Critical System Tests
        run: |
          python -m pytest \
            -m "critical" \
            --junitxml=test-results/junit-critical.xml \
            --html=test-results/report-critical.html \
            --self-contained-html \
            --maxfail=1 \
            --timeout=${{ env.TEST_TIMEOUT }} \
            -v \
            tests/
        env:
          TEST_BASE_URL: ${{ needs.setup-test-environment.outputs.test-url }}

      - name: 📊 Upload Test Results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: critical-test-results
          path: test-results/
          retention-days: 30

  generate-test-report:
    name: 📋 Generate Test Report
    runs-on: ubuntu-latest
    needs: [api-integration-tests, database-integration-tests, container-integration-tests, monitoring-tests, critical-tests]
    if: always()
    timeout-minutes: 10
    
    steps:
      - name: 📥 Checkout Repository
        uses: actions/checkout@v4

      - name: 📥 Download All Test Results
        uses: actions/download-artifact@v4
        with:
          path: all-test-results/

      - name: 📋 Generate Comprehensive Report
        run: |
          mkdir -p comprehensive-report
          
          # Create comprehensive test report
          cat > comprehensive-report/index.html << 'EOF'
          <!DOCTYPE html>
          <html>
          <head>
              <title>SafeWork Integration Test Report</title>
              <meta charset="utf-8">
              <style>
                  body { font-family: Arial, sans-serif; margin: 20px; background: #f5f5f5; }
                  .container { max-width: 1200px; margin: 0 auto; background: white; padding: 20px; border-radius: 8px; box-shadow: 0 2px 10px rgba(0,0,0,0.1); }
                  .header { background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white; padding: 20px; border-radius: 8px; margin-bottom: 20px; }
                  .status-success { color: #28a745; font-weight: bold; }
                  .status-warning { color: #ffc107; font-weight: bold; }
                  .status-error { color: #dc3545; font-weight: bold; }
                  .test-category { background: #f8f9fa; padding: 15px; margin: 10px 0; border-radius: 5px; border-left: 4px solid #007bff; }
                  .metrics { display: grid; grid-template-columns: repeat(auto-fit, minmax(200px, 1fr)); gap: 15px; margin: 20px 0; }
                  .metric-card { background: #f8f9fa; padding: 15px; border-radius: 8px; text-align: center; }
                  .metric-value { font-size: 2em; font-weight: bold; color: #007bff; }
                  .timestamp { font-size: 0.9em; color: #6c757d; }
                  ul { margin: 10px 0; padding-left: 20px; }
                  li { margin: 5px 0; }
                  a { color: #007bff; text-decoration: none; }
                  a:hover { text-decoration: underline; }
              </style>
          </head>
          <body>
              <div class="container">
                  <div class="header">
                      <h1>🧪 SafeWork Integration Test Report</h1>
                      <p class="timestamp">Generated: $(date -u)</p>
                      <p>Workflow: ${{ github.workflow }}</p>
                      <p>Commit: ${{ github.sha }}</p>
                  </div>
                  
                  <div class="metrics">
                      <div class="metric-card">
                          <div class="metric-value">$(find all-test-results -name "junit-*.xml" | wc -l)</div>
                          <div>Test Suites</div>
                      </div>
                      <div class="metric-card">
                          <div class="metric-value">$(find all-test-results -name "report-*.html" | wc -l)</div>
                          <div>Test Reports</div>
                      </div>
                      <div class="metric-card">
                          <div class="metric-value">$(find all-test-results -name "coverage-*.xml" | wc -l)</div>
                          <div>Coverage Reports</div>
                      </div>
                  </div>
                  
                  <div class="test-category">
                      <h2>Test Categories</h2>
                      <ul>
          EOF
          
          # Add test category results
          for category in api database container monitoring e2e critical; do
            if find all-test-results -name "*${category}*" -type d | grep -q .; then
              echo "                  <li class=\"status-success\">✅ ${category^} Integration Tests</li>" >> comprehensive-report/index.html
            else
              echo "                  <li class=\"status-warning\">⚠️ ${category^} Integration Tests - Skipped</li>" >> comprehensive-report/index.html
            fi
          done
          
          cat >> comprehensive-report/index.html << 'EOF'
                      </ul>
                  </div>
                  
                  <div class="test-category">
                      <h2>📊 Test Reports</h2>
                      <ul>
          EOF
          
          # Add links to test reports
          find all-test-results -name "report-*.html" | while read -r report; do
            basename=$(basename "$report")
            category=$(echo "$basename" | sed 's/report-\(.*\)\.html/\1/')
            echo "                  <li><a href=\"../${report}\">📋 ${category^} Test Report</a></li>" >> comprehensive-report/index.html
          done
          
          cat >> comprehensive-report/index.html << 'EOF'
                      </ul>
                  </div>
                  
                  <div class="test-category">
                      <h2>📈 Coverage Reports</h2>
                      <ul>
          EOF
          
          # Add links to coverage reports
          find all-test-results -name "coverage-*" -type d | while read -r coverage_dir; do
            basename=$(basename "$coverage_dir")
            category=$(echo "$basename" | sed 's/coverage-\(.*\)/\1/')
            echo "                  <li><a href=\"../${coverage_dir}/index.html\">📊 ${category^} Coverage Report</a></li>" >> comprehensive-report/index.html
          done
          
          cat >> comprehensive-report/index.html << 'EOF'
                      </ul>
                  </div>
                  
                  <div class="test-category">
                      <h2>ℹ️ Workflow Information</h2>
                      <ul>
                          <li><strong>Repository:</strong> ${{ github.repository }}</li>
                          <li><strong>Branch:</strong> ${{ github.ref_name }}</li>
                          <li><strong>Commit SHA:</strong> ${{ github.sha }}</li>
                          <li><strong>Workflow Run:</strong> ${{ github.run_number }}</li>
                          <li><strong>Actor:</strong> ${{ github.actor }}</li>
                      </ul>
                  </div>
              </div>
          </body>
          </html>
          EOF

      - name: 📊 Upload Comprehensive Report
        uses: actions/upload-artifact@v4
        with:
          name: comprehensive-test-report
          path: |
            comprehensive-report/
            all-test-results/
          retention-days: 30

      - name: 💬 Comment PR with Results
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            
            // Count test results
            const testSuites = require('child_process').execSync('find all-test-results -name "junit-*.xml" | wc -l').toString().trim();
            const testReports = require('child_process').execSync('find all-test-results -name "report-*.html" | wc -l').toString().trim();
            
            const comment = `## 🧪 Integration Test Results
            
            **Test Summary:**
            - 📋 Test Suites: ${testSuites}
            - 📊 Test Reports: ${testReports}
            - 🔗 [View Comprehensive Report](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }})
            
            **Test Categories:**
            - ✅ API Integration Tests
            - ✅ Database Integration Tests  
            - ✅ Container Integration Tests
            - ✅ Monitoring Tests
            - ✅ Critical System Tests
            
            All integration tests have been executed. Check the artifacts for detailed reports.`;
            
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: comment
            });

  notify-results:
    name: 📢 Notify Results
    runs-on: ubuntu-latest
    needs: [generate-test-report]
    if: always() && (github.event_name == 'schedule' || github.event_name == 'workflow_dispatch')
    
    steps:
      - name: 📢 Notify Success
        if: needs.generate-test-report.result == 'success'
        run: |
          echo "✅ Integration tests completed successfully!"
          echo "📊 Reports available in workflow artifacts"
      
      - name: 📢 Notify Failure
        if: needs.generate-test-report.result == 'failure'
        run: |
          echo "❌ Integration tests failed!"
          echo "🔍 Check workflow logs for details"
          exit 1