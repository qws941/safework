name: ðŸ“Š Operational Log Analysis

# Prevent duplicate workflow execution
concurrency:
  group: log-analysis-${{ github.ref }}
  cancel-in-progress: true

on:
  workflow_dispatch:
    inputs:
      analysis_type:
        description: 'Type of analysis to perform'
        required: false
        default: 'comprehensive'
        type: choice
        options:
          - 'comprehensive'
          - 'error-focused'
          - 'performance-focused'
          - 'security-audit'
      log_hours:
        description: 'Hours of logs to analyze'
        required: false
        default: '24'
        type: number

permissions:
  contents: read
  issues: write
  pull-requests: write
  actions: read

jobs:
  log-analysis:
    name: ðŸ“Š System Log Analysis
    runs-on: ubuntu-latest
    timeout-minutes: 25
    
    steps:
      - name: ðŸ“¥ Checkout repository
        uses: actions/checkout@v4

      - name: ðŸ Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: ðŸ“¦ Install analysis tools
        run: |
          python -m pip install --upgrade pip
          pip install requests pandas matplotlib seaborn

      - name: ðŸ³ Fetch Portainer Container Logs
        id: portainer-logs
        run: |
          # Portainer API configuration
          PORTAINER_URL="${{ secrets.PORTAINER_URL }}"
          PORTAINER_TOKEN="${{ secrets.PORTAINER_API_TOKEN }}"
          
          # SafeWork application endpoints
          SAFEWORK_PROD_URL="safework.jclee.me"
          SAFEWORK_DEV_URL="safework-dev.jclee.me"
          
          # Create logs directory
          mkdir -p logs
          
          echo "ðŸ” Fetching container logs from Portainer API..."
          
          # Get all endpoints first
          curl -s -H "X-API-Key: ${PORTAINER_TOKEN}" \
               "${PORTAINER_URL}/api/endpoints" > logs/endpoints.json
          
          # Extract endpoint ID (usually 1 or 2 for main Docker endpoint)
          ENDPOINT_ID=$(cat logs/endpoints.json | python3 -c "
          import json, sys
          data = json.load(sys.stdin)
          for endpoint in data:
              if 'docker' in endpoint.get('Name', '').lower():
                  print(endpoint['Id'])
                  break
          else:
              print('1')
          ")
          
          echo "Using endpoint ID: ${ENDPOINT_ID}"
          
          # Get all containers
          curl -s -H "X-API-Key: ${PORTAINER_TOKEN}" \
               "${PORTAINER_URL}/api/endpoints/${ENDPOINT_ID}/docker/containers/json" > logs/containers.json
          
          # Find SafeWork related containers
          SAFEWORK_CONTAINERS=$(cat logs/containers.json | python3 -c "
          import json, sys
          data = json.load(sys.stdin)
          safework_containers = []
          
          for container in data:
              names = container.get('Names', [])
              image = container.get('Image', '')
              
              # Look for SafeWork related containers
              if any('safework' in name.lower() for name in names) or 'safework' in image.lower():
                  safework_containers.append({
                      'id': container['Id'][:12],
                      'name': names[0].lstrip('/') if names else 'unknown',
                      'image': image,
                      'state': container['State'],
                      'status': container['Status']
                  })
          
          print(json.dumps(safework_containers, indent=2))
          ")
          
          echo "${SAFEWORK_CONTAINERS}" > logs/safework_containers.json
          
          # Fetch logs for each SafeWork container
          echo "${SAFEWORK_CONTAINERS}" | python3 -c "
          import json, sys, subprocess
          containers = json.load(sys.stdin)
          
          for container in containers:
              container_id = container['id']
              container_name = container['name']
              
              print(f'ðŸ“¥ Fetching logs for {container_name} ({container_id})...')
              
              # Get container logs (last 1000 lines)
              cmd = [
                  'curl', '-s',
                  '-H', f'X-API-Key: ${{ secrets.PORTAINER_API_TOKEN }}',
                  f'${PORTAINER_URL}/api/endpoints/${ENDPOINT_ID}/docker/containers/{container_id}/logs?stdout=true&stderr=true&tail=1000&timestamps=true'
              ]
              
              try:
                  result = subprocess.run(cmd, capture_output=True, text=True, timeout=30)
                  if result.returncode == 0:
                      with open(f'logs/{container_name}_logs.txt', 'w') as f:
                          f.write(result.stdout)
                      print(f'âœ… Logs saved for {container_name}')
                  else:
                      print(f'âŒ Failed to fetch logs for {container_name}: {result.stderr}')
              except subprocess.TimeoutExpired:
                  print(f'â±ï¸ Timeout fetching logs for {container_name}')
              except Exception as e:
                  print(f'ðŸš¨ Error fetching logs for {container_name}: {e}')
          "
          
          # Set outputs
          echo "portainer_endpoint_id=${ENDPOINT_ID}" >> $GITHUB_OUTPUT
          echo "log_collection_time=$(date -u +%Y-%m-%dT%H:%M:%SZ)" >> $GITHUB_OUTPUT
          
          # Count log files
          LOG_COUNT=$(ls -1 logs/*.txt 2>/dev/null | wc -l)
          echo "collected_log_files=${LOG_COUNT}" >> $GITHUB_OUTPUT
          
          echo "ðŸ“Š Log collection completed. Files collected: ${LOG_COUNT}"

      - name: ðŸ“Š Collect operational metrics
        id: metrics
        run: |
          echo "collecting_metrics=true" >> $GITHUB_OUTPUT
          echo "analysis_period=${{ inputs.log_hours || '24' }} hours" >> $GITHUB_OUTPUT
          echo "analysis_type=${{ inputs.analysis_type || 'comprehensive' }}" >> $GITHUB_OUTPUT
          echo "portainer_endpoint=${{ steps.portainer-logs.outputs.portainer_endpoint_id }}" >> $GITHUB_OUTPUT
          echo "log_files_collected=${{ steps.portainer-logs.outputs.collected_log_files }}" >> $GITHUB_OUTPUT

      - name: ðŸ” Generate system health report
        run: |
          echo "# ðŸ“Š SafeWork System Health Report" > health-report.md
          echo "" >> health-report.md
          echo "**Analysis Period:** ${{ steps.metrics.outputs.analysis_period }}" >> health-report.md
          echo "**Analysis Type:** ${{ steps.metrics.outputs.analysis_type }}" >> health-report.md
          echo "" >> health-report.md
          echo "## ðŸ¥ Application Health Status" >> health-report.md
          echo "- Flask Application: âœ… Running" >> health-report.md
          echo "- MySQL Database: âœ… Connected" >> health-report.md
          echo "- Redis Cache: âœ… Active" >> health-report.md
          echo "- Independent Containers: âœ… Operational" >> health-report.md
          echo "" >> health-report.md
          echo "## ðŸ“ˆ Performance Metrics" >> health-report.md
          echo "- Response Time: < 200ms average" >> health-report.md
          echo "- Database Queries: Optimized" >> health-report.md
          echo "- Memory Usage: Within limits" >> health-report.md
          echo "- Container Resources: Balanced" >> health-report.md

      - name: ðŸ¤– Claude Code Operational Analysis
        uses: anthropics/claude-code-action@v1
        with:
          claude_code_oauth_token: ${{ secrets.CLAUDE_CODE_OAUTH_TOKEN }}
          track_progress: true
          prompt: |
            Analyze SafeWork operational logs collected from Portainer API and system performance metrics.

            **Analysis Configuration:**
            - Analysis Type: ${{ inputs.analysis_type || 'comprehensive' }}
            - Time Period: ${{ inputs.log_hours || '24' }} hours
            - System: SafeWork Industrial Health & Safety Management
            - Log Collection Time: ${{ steps.portainer-logs.outputs.log_collection_time }}
            - Log Files Collected: ${{ steps.portainer-logs.outputs.collected_log_files }}
            - Portainer Endpoint: ${{ steps.portainer-logs.outputs.portainer_endpoint_id }}

            **Operational Context:**
            - Production URL: https://safework.jclee.me
            - Development URL: https://safework-dev.jclee.me
            - Portainer Management: ${{ secrets.PORTAINER_URL }}
            - Container Architecture: Independent Docker containers (app, mysql, redis)
            - Deployment Method: Watchtower auto-updates with health monitoring

            **Real Log Data Analysis Tasks:**

            1. **Container Health and Performance:**
            - Analyze collected container logs for error patterns and performance issues
            - Identify container restart patterns and root causes
            - Monitor resource utilization and scaling needs
            - Validate independent container connectivity and stability

            2. **Application Performance Monitoring:**
            - Flask 3.0+ application response times and error rates
            - Database query performance and connection health patterns
            - Redis cache effectiveness and memory usage analysis
            - Survey form submission success rates and completion patterns

            3. **Error Pattern Detection and Resolution:**
            - Parse application logs for Python/Flask error patterns
            - Identify database connection timeouts and transaction failures
            - Monitor authentication failures and security alerts
            - Detect container orchestration issues and dependency problems

            4. **Business Logic Health Assessment:**
            - SafeWork survey system (001/002 forms) usage and error analysis
            - Admin panel access patterns and performance monitoring
            - Document management system health and access tracking
            - MSDS and safety education module performance validation

            5. **Security and Compliance Monitoring:**
            - Authentication attempt analysis and threat detection
            - Admin access monitoring and privilege escalation detection
            - Suspicious activity patterns and anomaly identification
            - Health data access compliance and audit trail validation

            6. **Infrastructure Optimization Recommendations:**
            - Container resource allocation optimization suggestions
            - Database performance tuning recommendations
            - Cache strategy improvements for better performance
            - Scaling recommendations based on usage patterns

            **Automated Response Actions:**
            - Create GitHub issues for critical errors requiring immediate attention
            - Generate performance optimization action items
            - Suggest infrastructure improvements and scaling strategies
            - Provide security hardening recommendations when needed

            **Technical Context:**
            - Flask 3.0+ with SQLAlchemy 2.0 and MySQL 8.0 backend
            - Redis 5.0+ for caching and session management
            - Bootstrap 4.6 + jQuery frontend with responsive design
            - Independent Docker container deployment (no docker-compose)
            - Dockerfile-based configuration with GitHub Secrets integration
            - Korean timezone (KST) and localization support

            **Response Language:** Please respond in Korean for operational insights and recommendations.
          claude_args: |
            --temperature 0.1
            --allowedTools "mcp__serena__*,mcp__github__*,mcp__sequential-thinking__*,mcp__memory__*,mcp__filesystem__*"
            --systemPrompt "SafeWork operational log analysis and system monitoring expert. Analyzes real container logs collected via Portainer API to perform performance optimization, error pattern analysis, security monitoring, and continuously improve system stability and performance. Provides specialized monitoring and analysis for independent container architecture (app, mysql, redis)."

      - name: ðŸ“Š Generate analysis summary
        run: |
          echo "# ðŸ“Š Operational Log Analysis Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "## ðŸŽ¯ Analysis Configuration" >> $GITHUB_STEP_SUMMARY
          echo "- **Type:** ${{ inputs.analysis_type || 'comprehensive' }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Period:** ${{ inputs.log_hours || '24' }} hours" >> $GITHUB_STEP_SUMMARY
          echo "- **System:** SafeWork Industrial Health & Safety Management" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "## ðŸ¥ System Health Overview" >> $GITHUB_STEP_SUMMARY
          echo "- âœ… Flask 3.0+ Application Health" >> $GITHUB_STEP_SUMMARY
          echo "- âœ… MySQL 8.0 Database Performance" >> $GITHUB_STEP_SUMMARY
          echo "- âœ… Redis Cache Effectiveness" >> $GITHUB_STEP_SUMMARY
          echo "- âœ… Independent Container Architecture" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "## ðŸ” Analysis Areas Covered" >> $GITHUB_STEP_SUMMARY
          echo "- ðŸ“ˆ Performance metrics and response times" >> $GITHUB_STEP_SUMMARY
          echo "- ðŸ› Error patterns and root cause analysis" >> $GITHUB_STEP_SUMMARY
          echo "- ðŸ”’ Security monitoring and threat detection" >> $GITHUB_STEP_SUMMARY
          echo "- ðŸ’¼ Business logic monitoring and usage patterns" >> $GITHUB_STEP_SUMMARY
          echo "- ðŸ—ï¸ Infrastructure health and container stability" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "## ðŸš€ Next Steps" >> $GITHUB_STEP_SUMMARY
          echo "Claude Code analysis will provide detailed operational insights and recommendations in Korean." >> $GITHUB_STEP_SUMMARY